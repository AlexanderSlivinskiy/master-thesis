\chapter{Results} \label{ch:results}

\textcolor{red}{Include $\SI$ as an okay alternative to BVI}
\textcolor{red}{Try to verify that $\LPSI$ may be bad. The best way to argue about this is that we get out-of-memory errors. This also is what Gandalf said about memory: LP takes more.}

In this chapter, we analyze models regarding their feature distribution and algorithms regarding their performance.
Furthermore, we investigate which model features influence the performance of the algorithms.

%Regarding runtime a lot of stuff may change. Iterations wont change as long as we use the same deterministic algorithms, so its a more stable metric.

%Various studies we have made, knit into a nice purple string and story. Here might appear:
%Maybe it would also be cool to show preformance differences in real case studies in comparison to the randomly generated models and make conclusions Ideally:
%\textcolor{purple}{We did previously not have enough models to see behaviour XYZ but now we can.}

\section{Experimental setup}
Various algorithms we consider were already implemented in PRISM-games~\cite{prismgames3}.
We extended PRISM-games by the algorithms $\LPSI$, $\TLPSI$, and $\TOPAlg$.
Moreover, for $\TOPAlg$ we added precise Markov chain solving, which was not present in PRISM before, and extended the strategy iteration (which was implemented in~\cite{gandalf}) to use this precise solving.
Our code is available in the GitHub repository \url{https://github.com/ga67vib/Algorithms-For-Stochastic-Games}.

\subsubsection*{Technical details}
We conducted the experiments on a server with 64 GB of RAM and a 3.60GHz Intel CPU running Manjaro Linux. %Intel (R) Xeon(R) W-2123 CPU.
We always use a precision of $\varepsilon=10^{-6}$. The timeout was set to 15 minutes for all models. 
The memory limit for every experiment was 6 GB.

\subsection{Case studies}
We consider case studies from three different sources: 
(i) all real case studies that were already used in~\cite{gandalf}, which are mainly from the PRISM benchmark suite~\cite{PRISMben}.
For a detailed description of the real case studies see Appendix \ref{sec:appendix}
We omit models that are already solved by pre-computations.
(ii) several handcrafted corner case models: haddad-monmege (an adversarial model for value iteration from~\cite{haddadmonmege}), BigMec (a single big MEC), and MulMec (a long chain of many small MECs), the latter two both being from~\cite{gandalf}.
(iii) randomly generated models generated by Algorithm \ref{alg:randomRandom} and our additional guidelines from Subsection \ref{sec:guidelines}.

\textcolor{red}{Here we should state the exact parameters we have used for our models. States are 1000 to 10000, transition probabilities between 0.1 and 0.01 etc.}

\subsection{Plot overview} \label{subsec:plots}
We provide a short description of each type of plot we use in this chapter:
\subsubsection*{Box plots} \label{plot:boxplot}
A box plot provides an overview of the spread and skewness of the model features of our model sets.
The orange line marks the median of a feature in all models and the green triangle marks the
average. The bounds of the boxes mark the 25 and 75 percentile, and the lines extended
by the whiskers mark the 10 and 90 percentile. Dots outside of whiskers represent
outliers that differ significantly from the rest of the dataset.
The plots grouped and colored into the following categories:
\begin{itemize}
    \item Green outlines are for properties related to states. 
    \item Blue outlines are for properties related to Actions. 
    \item Cyan outlines are for properties related to Transitions.
    \item Red outlines are for properties related to MECs.
    \item Orange outlines are for properties related to SECs. 
\end{itemize}

\subsubsection*{Line plots for algorithm performance} \label{plot:starplot}
To provide a general overview performance of all stochastic game algorithms, we use line plots.
The plot depicts the number of solved benchmarks (x-axis) and the time it took to solve them (y-axis). 
For each algorithm, the benchmarks are sorted ascending by verification time. A line stops when no further benchmarks could be solved.
Intuitively, the further to the bottom right a plot is, the better; where going right (solving benchmarks) is more relevant.
The legend on the right is sorted by the performance of the algorithms in descending order.
Note that this plot has to be interpreted with care, as it greatly depends on the selection of benchmarks.

\subsubsection*{Scatter plots for algorithm performance} \label{plot:performanceScatter}
While the line plot compares models solved and accumulated performance, the scatter plots allow us to compare algorithm performance model by model.
Each point in the graph is a model. The x-axis marks the time one algorithm requires to solve a model, and the y-axis marks the respective time of the compared algorithms.
If a point is below the diagonal, the algorithm on the x-axis required more time to solve it than the corresponding algorithm on the y-axis and vice versa.
The two lines next to the diagonal mark the case where one algorithm was twice as fast as the other.

\subsubsection*{1-dimensional scatter plots} \label{plot:1Dscatter}
\textcolor{red}{This is very abstract, and I do not like it. If you use it only once you can move it down OR put it into an own subsection OR reference it only once}
In some cases we want to analyze how two sets $\mathbf{A}, \mathbf{B}$ correlate to model features. 
Usually, we use $\mathbf{B}$ as the complement to $\mathbf{A}$.
An example for such a pair is: 
$\mathbf{A}$ contains all the models where algorithm X was 1.5 times faster than algorithm Y.
$\mathbf{B}$ contains all the models where algorithm X was not 1.5 times faster than algorithm Y.
Next, we study the properties of the models in $\mathbf{A}$ and the properties of the models in $\mathbf{B}$ 
by using a 1-dimensional scatter plot. When using this plot, we try to identify whether models in $\mathbf{A}$ distribute
differently along the spectrum of feature values than $\mathbf{B}$.
In our example may find for example that all models $\mathbf{A}$ have smaller MECs than models in $\mathbf{B}$. 

\section{Model analysis results}
First, we want to learn about the feature distribution of the real case studies we have. 
For this we use a box plot for each feature in Figure \ref{fig:Real_FeatureDistribution}.
In each graph, the distribution of the values of one separate feature in all real case studies is visualized. 
The orange line marks the median of a feature in all models and the green triangle marks the average.
The bounds of the boxes mark the 25 and 75 percentile, and the lines extended by the whiskers mark the 10 and 90 percentile.
%\textcolor{red}{Not sure about the 10 and 90 percentiles}
Dots outside of whiskers represent outliers.
For example, the relative number of probabilistic actions is between around $15\%$ and $45\%$ in half of the models.
In half of the models, more than $20\%$ of actions are probabilistic.
\textcolor{purple}{Most likely I may move all the features into the appendix and only highlight 5-10 cool features.}
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{figures/Real_FeatureDistribution.jpg}
    \caption[Feature Distribution of the case studies]{
        Box plot of the feature distribution of the real case studies. For a description on how to read the plot is provided in Section \ref{plot:boxplot}.
        The evaluation of the plot is located in Section \ref{insights:realDistribution}.
    }
    \label{fig:Real_FeatureDistribution}
\end{figure}
\FloatBarrier
The box plot provides the following insights:
\begin{itemize} \label{insights:realDistribution}
    \item According to AvgNumActionsPerState and AvgNumTransPerAction, models have on average 2 actions per state and 1.5 transitions per action
    \item According to NumUnknown, on average 80\% of the states of the models are trivial, and their value can be computed with simple graph algorithms 
    \item Generally, the number of states is evenly split between Maximizer and Minimizer
    \item According to NumProbActions, usually around 70 to 85\% of all actions are deterministic
    \item According to NumMECs, most models do not contain end components
\end{itemize}

By furthermore printing the maximal and minimal occurring values of each feature we obtain that the smallest occurring positive transition probability is 0.001.

With also use the information to draw conclusions about which structural cases do not appear in the real case studies. 
None of the models contain these cases:
\begin{itemize}
    \item Models with numerous actions per state
    \item Models with numerous Transitions per action
    \item Models with very small transition probabilities
\end{itemize}

Furthermore, we use box plots to evaluate for which features our random generation algorithm from Chapter \ref{ch:randomGen} is biased.
Figure \ref{fig:Random_FeatureDistribution} contains the box plots for our randomly generated models.
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{figures/RandomRandom_FeatureDistribution.jpg}
    \caption[Feature Distribution of random models]{
        Feature Distribution of randomly generation models by Algorithm \ref{alg:randomRandom}. For a description on how to read the plot is provided in Section \ref{plot:boxplot}.
        The evaluation of the plot is located in Section \ref{insights:randomRandom}.
    }
    \label{fig:Random_FeatureDistribution}
\end{figure}
\FloatBarrier

The biases we read from this plot are:
\begin{itemize} \label{insights:randomRandom}
    \item On average, 38.5\% of the states of the models can be computed by trivial graph algorithms. NumSinks shows that almost all known states are sinks.
    \item With the chosen parameters, our algorithm generates models with 2 actions per state on average
     and 2 transitions per action on average.     
     However, our parameters allows us to change the number of actions and transitions per state.
    \item NumNonSingleton shows that in almost all cases there is only one strongly connected component.
        This is because we uniformly randomize where a transition may lead. Thus, it is likely that big SCCs are formed. 
        If necessary, the RandomSCC guideline can control the size of the SCCs.
    \item NumMECs indicates that there is usually either one MEC or none at all. Also, the MECs tend to have very few states (usually no more than 2).
    However, there are parameter configurations such that we form bigger MECs. For example setting the parameters in such a way that the actions are deterministic
    and adding an action to every state in the backwards procedure of Algorithm \ref{alg:randomRandom} creates models with a high tendency of forming few MECs that usually contain the whole state-space.
    Nevertheless, without providing a specific guideline, we have very limited control over the number and size of the MECs.
    \item Our random generation algorithm introduces a bias towards various properties like the number of SCCs or the average number of transitions per action.
    While on average models have only two actions, the maximal number of actions a state has is usually between 20 and 22.
    When analyzing the number of actions in relation to the state index, states with many actions always have low indices.
\end{itemize}



To regain control over these properties, other guidelines as described in Section \ref{sec:guidelines}.
\textcolor{red}{Show the Figure of SCC FeatureDistribution for RandomSCC benches.}
However, when comparing the feature distributions of the real case studies and the distributions of the models generated by Algorithm \ref{alg:randomRandom},
they have similar biases for many features. Both benchmarks tend to have few big SCCs, few actions per state, and few transitions per action.
Thus, Algorithm \ref{alg:randomRandom} is capable of recreating models that have in various regards a similar structure to the currently available real case studies. 
\textcolor{purple}{Actually, we might use one box plot for both models}

\section{Algorithm comparison results}

In this section, we compare the Algorithms introduced in Section \ref{sec:SGAlgos} on real case studies, handcrafted examples, and our randomly generated models to both evaluate the 
performance of the algorithms relative to each other and find correlations between model feature values and algorithm performance.

First, we provide a general overview of the performance of all algorithms on our benchmarking set in Figure \ref{fig:AlgoPerformance}.
The plots depict the number of solved benchmarks (x-axis) and the time it took to solve them (y-axis). 
For each algorithm, the benchmarks are sorted ascending by verification time. A line stops when no further benchmarks could be solved.
Intuitively, the further to the bottom right a plot is, the better; where going right (solving benchmarks) is more relevant.
The legend on the right is sorted by the performance of the algorithms.
Note that this plot has to be interpreted with care, as it greatly depends on the selection of benchmarks.
\textcolor{purple}{Should make the both plots for real and random in jupyter next to each other. This gives the best quality screenshots. If not possible then at least make the height smaller}
\begin{figure}
    \centering
    \subfloat[\centering Performance Overview on real case studies]{{\includegraphics[width=0.8\textwidth]{figures/Real_AlgoPerformance.png} }}%
    \qquad
    \subfloat[\centering Performance Overview on randomly generated models]{{\includegraphics[width=0.8\textwidth]{figures/RandomRandom_AlgoPerformance.png} }}%
    \caption[Overview of Algorithm Performance]{Overview of Algorithm Performance}%
    \label{fig:AlgoPerformance}
\end{figure}

%For value-iteration-based algorithms, we provide the same graph with the number of iterations required to solve the models on the y-axis in Figure
%\ref{fig:AlgoPerformanceIters} \textcolor{red}{Add star-graph for iterations}.

We read several clues from Figure \ref{fig:AlgoPerformance}: 
$\WP$, $\OVI$, and $\TLPSI$ seem to be the most performant algorithms for our benchmarks. 
Also, Optimizations mentioned in Subsection \ref{subsec:optimizations} do not seem to have in general a positive impact on their baseline algorithms.

We split our analysis into three subtopics: 
First, we compare the three value-iteration-based algorithms with guarantees $\OVI$, $\WP$, and $\BVI$. 
Then, we analyze the impact of the optimizations from Subsection \ref{subsec:optimizations} on their respective baseline algorithms.
Lastly, we investigate the performance of $\LPSI$ and $\TLPSI$ in comparison to value-iteration-based algorithms.


\subsection{$\BVI$ vs $\OVI$ vs $\WP$}
We can read from Figure \ref{fig:AlgoPerformance} that WP is the fastest to solve the problems on both random-generated models and real case studies.
To see whether this is the case for all models or only when accumulating runtime, we consider the scatter plot in Figure \ref{fig:WPvsBVIandOVIonRandomRandom}.
Each point in the graph is a model. The x-axis marks the time $\WP$ requires to solve the stochastic game, and the y-axis marks the respective time $\BVI$ or $\OVI$.
The two lines next to the diagonal mark the case that $\WP$ is twice as fast as $\BVI$ / $\OVI$s or half as fast.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\textwidth]{figures/WPvsBVIandOVIonAll.png}
    \caption[$\WP$ compared to $\BVI$ and $\OVI$ on time necessary to solve models]{
        $\WP$ compared to $\BVI$ and $\OVI$ on time necessary to solve models
    }
    \label{fig:WPvsBVIandOVIonRandomRandom}
\end{figure}

$\WP$ is usually faster than $\BVI$ and $\OVI$ and never requires more than twice as long.
We are interested in whether there is a correlation between structural properties and $\WP$ being better or worse than the other two.
To inspect the cases where $\WP$ is better than $\OVI$ or the other way around, we plot the feature of the models where one algorithm was at least
1.5 times faster than the other one. Figure \ref{fig:WPvsOVIon1DFeatureScatter} visualizes these cases. 
The red dots mark models where $\OVI$ is at least 1.5 times faster than $\WP$, and the green dots mark models where $\WP$ is at least 1.5 times faster than $\OVI$.
The x-axis displays the range of values that occur for the feature. 
If the dots are clustered for a feature, either one algorithm was only faster if the model had this kind of structural composition, 
or there are only discrete values available for the feature. For example, the number of states is mostly discrete because the random models depend on an input parameter.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\textwidth]{figures/WPvsOVIon1DFeatureScatter.png}
    \caption[$\WP$ compared to $\OVI$]{
        The red dots mark models where $\OVI$ is at least 1.5 times faster than $\WP$, and the green dots mark models where $\WP$ is at least 1.5 times faster than $\OVI$.
        The x-axis displays the range of values that occur for the feature. 
        If the dots are clustered for a feature, either one algorithm was only faster if the model had this kind of structural composition, 
        or there are only discrete values available for the feature. For example, the number of states is mostly discrete because the random models depend on an input parameter.
    }
    \label{fig:WPvsOVIon1DFeatureScatter}
\end{figure}

According to Figure \ref{fig:WPvsOVIon1DFeatureScatter}, $\WP$ was better than $\OVI$ if the model had more states, had big MECs and big SCCs.
$\OVI$ seems to be better if the furthest target is far away from the initial state, but since we cannot tie this to any structural significant property,
it may also be noise. If this interpretation is correct, $\WP$ should become even better than $\OVI$ if we use larger models.

The same plot for $\WP$ and $\BVI$ is harder to interpret since there are only two cases where $\BVI$ is 1.5 times faster than $\OVI$, and 40 cases
for the opposite event. Thus, we conclude that $\WP$ is overall more performant on our benchmarks than $\BVI$ regarding runtime. 
\textcolor{blue}{@Maxi: The two cases where BVI is better are quite noisy, so it is not worth including the Figure in my Opinion.
But I have added it in case you think it is interesting. It is Figure \ref{fig:WPvsBVIon1DFeatureScatter}}

\begin{figure}[t]
    \centering
    \includegraphics[width=1\textwidth]{figures/WPvsBVIon1DFeatureScatter.png}
    \caption[$\WP$ compared to $\BVI$]{
        Comparing cases where $\WP$ is better than $\BVI$ (green) and $\BVI$ is better than $\WP$ (red) 
        and plotting the corresponding feature values of the models.
    }
    \label{fig:WPvsBVIon1DFeatureScatter}
\end{figure}


However, time is not the best measure we can use to compare value-iteration-based approaches. 
This is because time may be very dependent on optimizations in the code. 
For value-iteration-based algorithms, we can also compare the iteration count, which depends only on the algorithm itself.
Thus, we provide an analogous scatter plot in Figure \textcolor{red}{ITERATION SCATTER} where the axes mark the iterations required to solve a model.

\textcolor{red}{Next, add big models to confirm that the hypothesis you set up also holds for big models. 
There you can also say that although $\OVI$ looks promising in the small models, in the big models it may fall behind $\BVI$ due to unlucky verification phases.}

\subsection{Analyzing the optimizations}

$\mathbf{Gauss-Seidel}$ for $\BVI$:

\textcolor{purple}{Generally fewer iterations, but matrix operations of vanilla is faster than state-by-state.
Can sometimes be worse even for iterations due to unlucky SECs based on lower bound. 
Reversing the order of computation for Gauss-Seidel or using a topological ordering could not improve our results. Show some graphs of how it did not improve}
\textcolor{purple}{Probably, Gauss-Seidel should be even worse for bigger models since there is more room for "not paying off" using state-by-state computation.}


$\mathbf{D}$ for $\BVI$:

\textcolor{purple}{Show time scatter, say two sentences (no huge improvement), go on}

$\mathbf{T}$ for $\BVI, \OVI$ and $\LPSI$:

As the scatter plot \textcolor{red}{Ref to scatter plot TLPSI vs LPSI} shows,
the topological addition for strategy iteration with linear programming in the real case studies and random models does 
neither in- nor decrease the performance of the algorithm considerably.
However, most models have very few SCCs, so the topological optimization does not contribute a lot.
The data point where $\TLPSI$ is significantly faster is on the real case study "dice", where every state is an SCC on its own.
This is obviously the best-case scenario for topological algorithms.
\textcolor{red}{Show Scatter.
Explain why $\OVI$ and $\BVI$ do not scale that well (explained in Gandalf Paper)}

$\TOPAlg$ for $\BVI$:

$\TOPAlg$ seems to perform worse than $\BVI$ in general. This is because we solve the DTMCs with exact methods. 
\textcolor{red}{Scatter BVI vs TOP.}
This requires a matrix inversion, which is an $\mathcal{O}(n^{2})$-operation, where n is the number of states in the SCC whose value is being computed.
The bottleneck becomes apparent if we consider a scatter plot where we show the runtime against the size of the biggest SCC as in Figure \ref{fig:} \textcolor{red}{ADD FEATURE-SCATTER}.
We have also tried solving the resulting MDP with linear programming instead of strategy iteration, but it was still worse than $\TLPSI$.

%There are several relations we read from Figure \ref{fig:AlgoPerformance}:
%\begin{itemize}
%    \item $\TLPSI$ is accumulated better than $\LPSI$.
%    \item $\TLPSI$ is performant for small models
%    \item $\WP$ is usually the best value iteration approach
%    \item $\OVI$ is usually better than $\BVI$ for small models
%    \item $\TOPAlg$ does not seem very promising
%    \item The optimizations do not seem to do much except for the topological switch for $\TLPSI$ and $\WP$
%    \item Why GBVI is not always better than BVI (iterationwise)
%\end{itemize}

\subsection{$\TLPSI$}
\textcolor{red}{It would also be interesting to see if more probabilistic loops affect $\LPSI$ as strong as VI}.

Although value iteration is usually regarded to be the most performant algorithm type for solving stochastic games, 
$\TLPSI$ yielded the best results alongside widest-path bounded value iteration.
Since strategy iteration simply tries to make an informed decision on which strategy to pick and solves the underlying MDP, 
we have to inspect the algorithms we use to solve MDPs - for $\TLPSI$ this is linear programming.

Linear programming scales worse than value iteration for huge models. \textcolor{purple}{To test this, we have 
run several benchmarks on models with state size 10 million and varying SCC sizes. [Now enter Feature-Performance Scatter Plot] 
The bigger the SCCs become, the slower $\TLPSI$ becomes. At a size of [...] per SCC, $\WP$ was faster than $\TLPSI$.}
Thus, we do not recommend using $\TLPSI$ on models with numerous states.
However, $\TLPSI$ may be a good complementary solution approach in case a model is especially hard for value iteration.
Also, the topological improvement allows solving models with huge numbers of small SCCs faster than value iteration.
\textcolor{purple}{And also value iteration was the focus of research for the last 20 years. 
LP could likely be improved. At the moment, we do not even deflate but use MIP to encode the maximum-best-exit constraints. But this should maybe go into future work}

\subsection{Big models}
\textcolor{red}{Might also put in somewhere else. Basically too little data but also pretty though PRISM constraints.
$\TLPSI$ ran sometimes out of stack (see memo comparation in GANDALF for QP or make own) suggesting that $\LPSI$ may not scale too well 
for bigger models but it may be good if there are many SCCs with smaller SCCs.
It seems that $\OVI$ does not scale too well. However, in the end it is very important to note that we are lacking the capacity to create
big models.}

\section{Searching correlations between algorithms and features}
Lastly, we are interested in correlations between algorithm performance and values of features.
Ideally, we would like to find cases where one algorithm scales better with certain features than others.
If we were to find enough such correlations, it would be possible to implement an efficient portfolio solver, which
would analyze the graph structure and decide based on the feature values which algorithm is most likely the best one to use in this case.
To find these correlations, we use the following visualization tools:

\textcolor{purple}{I am not really sure what I want to do with this section. 
But it would be a cool place to show algorithm-feature correlations and to show the ideas we applied to search for correlations.
Maybe I should instead make a separate section with all graph types that is easy to look up.}

\textcolor{red}{Maybe search for some scatters where the algorithms differ a lot and show them.}

\subparagraph*{Heatmaps}
Heatmaps visualize correlation matrices - matrices where one feature is mapped against another. The higher the correlation value, the stronger
a correlation between two features is. On the diagonal of the matrix, the correlation is maximal since there is a directly proportional correlation between
a feature and itself. Ideally, we would like to get clues from the heatmap which features or correlations we should investigate.
However, for the most part, we could not gather any non-trivial information from heatmaps. \textcolor{purple}{This is also tricky because
there is only one type of correlation that can be shown effectively: Most often we search for linear correlation with heatmaps. Thus,
if one feature depends in a non-linear fashion on another - for example if it rises quadratically - the correlation value may still be very low.}

\subparagraph*{Feature-performace scatter plots}
We plot algorithm runtime / iterations against feature values.

What is there to find in these graphs?
\begin{itemize}
    \item Clearly visible how TOP scales with SCC-size
    \item All scale with number of unknowns, which is no surprise but might be mentioned.
\end{itemize}

\subparagraph*{One dimensional scatter plots for features}
We can define two events A, B. Then we get models where A happens, models where B happens and then plot the feature values for models that are in set A or set B.
This way, we can find clusters and make conclusions like "If A happens, then the models have these feature values."