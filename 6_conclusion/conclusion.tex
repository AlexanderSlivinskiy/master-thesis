\chapter{Conclusion and future work} \label{ch:conclusion}
In this thesis we introduced a toolset to randomly generate models to enrich the structural variety of available models.
This enabled a broader and more precise comparison of the available solution algorithms.

Our randomly generated models can be in adjusted in a way that resembles the currently available case studies we are aware of.
At the same time, we are able to adjust the parameters and guidelines in such a way that they do express structural properties that differ from the case studies.
The only limit we face at the moment is that explicit models can be parsed only slowly in PRISM. 
To avoid this issue, we provide the option to prepend graphs at runtime.

Furthermore, we explored were helpful to analyze the growing set of both models and algorithms to analyze.
Establishing analysis tools allowed us to prototype algorithm ideas, assess fast whether it seems promising,
and provide a better overview of the data we collect. 
Additionally, our tools for model analysis improve with increasing data points.
This is not the case for tables as visualization and analysis tool, 
but they are nevertheless frequently the only utility used for visualization in analysis \cite{paperMaxi}\cite{widestPath}\cite{learningBased}.

Lastly, we have compared algorithms for $\SG$ solving and have found that although $\TLPSI$ is not competitive to $\OVI$, $\BVI$ and $\WP$ for large models,
it may be a good alternative for games that are adversarial to approached based on value iteration. 
Furthermore, it may be a good approach in case a model has many SCCs that are all of small size.

Like $\TLPSI$, $\OVI$ seemed promising for smaller models, but is likely not competitive with $\BVI$ or $\WP$ for most large models.
Together with the fact that $\BVI$ and $\WP$ can be stopped at any point and provide a guarantee on the precision, 
we conclude in general one should try $\BVI$ or $\WP$ when trying to solve a stochastic reachability game, 
and should pivot to other methods if these approaches struggle to converge.

\section*{Future work}
The model features we analyze at the moment helped us to draw some conclusions, but there are still many questions unanswered that would require
additional structural concepts and features that we track.
These questions are for example when to use Gauss-Seidel optimization or when to use $\WP$ instead of $\BVI$.

In addition, there are still many data analysis techniques we did not implement yet like stochastic tests or artificial intelligence algorithms
that can cluster features and find correlations between them. 

We believe more research of the correlation between algorithm performance and structural properties gives way to a portfolio solver which could first
analyze important structural features and then pick heuristically the most adapt algorithm to solve the problem.
With enough models, the decision which algorithm to use may be made by a neural network.
Also, combinations of algorithms like $\OVI$ and $\BVI$ could then be used effectively in a fitting scenario.
The user would have to pay the overhead for computing more vectors but may converge faster.

Since algorithm performance may change drastically depending on the models size,
we need to resolve the issue that our random generation process creates large explicit files which PRISM cannot handle.
The next step would be to create an optimization system to our random generation algorithm that would hold chunks of the data in 
implicit blocks to make the files easier parsable.

Lastly, at the moment, our random generation algorithm enforces a tendency of states with smaller indices to have more actions than states with higher indices.
Ideally, the user should be able to remove this restriction.
This could be addressed by introducing mechanisms like for example that a state $\stateMac_i$ can only be connected to states $\stateMac_{j}$ with $j \in [i-50, i+50]$.
Another way to improve the random generation algorithm is to find a method of reducing the models numbers of states that can be computed trivially.
\textcolor{purple}{I may also leave this out since I have nothing to say about it. We would simply generate less junk and more of the state space
would be used in a smart way instead of wasting it on trivially computed states we could have summarized into sinks and targets all along.} 