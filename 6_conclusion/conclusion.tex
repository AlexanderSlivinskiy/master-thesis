\chapter{Conclusion and future work} \label{ch:conclusion}
In this thesis we introduced a toolset to randomly generate models to enrich the structural variety of available models.
This enabled a broader and more precise comparison of the available solution algorithms.

Our randomly generated models can be in adjusted in a way that resembles the currently available case studies we are aware of.
At the same time, we are able to adjust the parameters and guidelines in such a way that they do express structural properties that differ from the case studies.
The only limit we face at the moment is that explicit models can be parsed only slowly in PRISM. 
To avoid this issue, we provide the option to prepend graphs at runtime.

Furthermore, we explored were helpful to analyze the growing set of both models and algorithms to analyze. \textcolor{red}{Sentence is wrong}
Establishing analysis tools allowed us to prototype algorithm ideas, assess fast whether it seems promising,
and provide a better overview of the data we collect. 
Additionally, our tools for model analysis improve with increasing data points.
This is not the case for tables as visualization and analysis tool, 
but they are nevertheless frequently the only utility used for visualization in analysis \cite{paperMaxi,widestPath,learningBased}.

Lastly, we have compared algorithms for $\SG$ solving and have found that although $\TLPSI$ is not competitive to $\OVI$, $\BVI$ and $\WP$ for large models,
it may be a good alternative for games that are adversarial to approached based on value iteration. 
Furthermore, it may be a good approach in case a model has many SCCs that are all of small size.

Like $\TLPSI$, $\OVI$ seemed promising for smaller models, but is likely not competitive with $\BVI$ or $\WP$ for most large models.
Together with the fact that $\BVI$ and $\WP$ can be stopped at any point and provide a guarantee on the precision, 
we conclude in general one should try $\BVI$ or $\WP$ when trying to solve a stochastic reachability game, 
and should pivot to other methods if these approaches struggle to converge.

\textcolor{purple}{
    Based on current results, the story may be this:
    \begin{enumerate}
        \item Big Scc, Big Mec, weakly connected: $\WP$ (ideal)
        \item Big Scc, Big Mec, strongly connected: $\WP$ (?)
        \item Big Scc, Small Mec, weakly connected: $\WP$ (?)
        \item Big Scc, Small Mec, strongly connected: $\OVI$ (ideal)
        \item Small Scc, Big Mec: (IMPOSSIBLE since MEC is SCC)
        \item Small Scc, Small Mec: ($\TLPSI$)
        \item Hard VI-problem (like hm): ($\TLPSI$)
        \item Where is $\BVI$ in this? 
    \end{enumerate}
}

\textcolor{purple}{egarding the red stuff: I think you could even have a table with rows Big SCC/small SCC and columns Big MEC/small MEC with subcolumns strongly/weakly connected, and enter the things you say; also indicating how certain you are of things. Maybe even referring to sections of exp where claims of "ideal" are backed up. So a cell would be "WP (ideal, see Sec 7.x.x, FIgure 7.y and 7.z)" or "WP (general recommendation, see Overview Line Plot)"
Then, you could say "Table shows what we currently believe". Point 7 can be separately stated, and your sentence above the red stuff can also stay in this or similar form, as it summarizes the table. But the table also sounds cool and is something Jan would love to have.}

\section*{Future work}
The model features we analyze at the moment helped us to draw some conclusions, but there are still many questions unanswered that would require
additional structural concepts and features that we track.
These questions are for example when to use Gauss-Seidel optimization or when to use $\WP$ instead of $\BVI$.

In addition, there are still many data analysis techniques we did not implement yet like stochastic tests or artificial intelligence algorithms
that can cluster features and find correlations between them. 

We believe more research on the correlation between algorithm performance and structural properties gives way to a portfolio solver which could first
analyze important structural features and then pick heuristically the most adapt algorithm to solve the problem.
With enough models, the decision which algorithm to use may be made by a neural network.
Also, combinations of algorithms like $\OVI$ and $\BVI$ could then be used effectively in a fitting scenario.
The user would have to pay the overhead for computing more vectors but may converge faster.

Since algorithm performance may change drastically depending on the models size,
we need to resolve the issue that our random generation process creates large explicit files which PRISM cannot handle.
The next step would be to create an optimization system to our random generation algorithm that would hold chunks of the data in 
implicit blocks to make the files easier parsable.

\textcolor{purple}{"Optimizatino system to our random generation" I was rather thinking of using more features of the PRISM language, e.g. taking advantage of modules. Can you add this suggestion in?}
\textcolor{purple}{The trivial thing is interesting and actually mathematically challenging, so I suggest to leave it in.}

Lastly, at the moment, our random generation algorithm enforces a tendency of states with smaller indices to have more actions than states with higher indices.
Ideally, the user should be able to remove this restriction.
This could be addressed by introducing mechanisms like for example that a state $\stateMac_i$ can only be connected to states $\stateMac_{j}$ with $j \in [i-50, i+50]$.
Another way to improve the random generation algorithm is to find a method of reducing the models numbers of states that can be computed trivially.
\textcolor{purple}{I may also leave this out since I have nothing to say about it. We would simply generate less junk and more of the state space
would be used in a smart way instead of wasting it on trivially computed states we could have summarized into sinks and targets all along.} 

\textcolor{purple}{Think about what the last sentence of your thesis should be. It should be something that leaves a good feeling in the belly of the reader. So not some detail of future work, but something more general.
Direction of "In conclusion, we have taken the first step towards better analysis of algorithms on SGs with our random generation, and there are many promising directions for improving this."
}