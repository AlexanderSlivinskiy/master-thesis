\chapter{Implemented Algorithm Extensions} \label{ch:implementedAlgos}
As part of the thesis, we have implemented the following extensions to Value Iteration and Strategy Iteration:

\subsubsection*{TOP} TOP as in \emph{topological and precise} is an extension to Value-Iteration-based algortihms that builds on top of the idea of topologicals sorting of \cite{Gandalf}.
We analyse the graph underlying the stochastic game, detect the strongly connected components (SCCs), and create a topological sorting based on the SCCs.
To ensure that every SCC provides an exact result to the next one, we take the $\epsilon$-precise values of the states of the finished SCC and compute all the
strategies that correspond to the given bounds of the states.
We can then fix each strategy separately, yielding two MDPs. We then perform one strategy iteration step on both MDPs. This step suggests to both MDPs the strategy
of the opponent and fixes it, yielding two Discrete-Time Markov Chains (DTMCs). We then solve the DTMCs by non-iterative, exact methods as described in \cite{BaierBook}.
If the values of both DTMCs are equal, we have both a guarantee that the strategies we would take are correct aswell aswell as the exact values of the states in the SCC.

\subsubsection*{Widest Path for Prism3}
Widest Path was introduced as an alternative to solving maximal end components for bounded value iteration \textcolor{purple}{Make sure you have introduced BVI}\cite*{WidestPath}.
We reimplemented it in the version of PRISM.

\subsubsection*{Linear Programming for MDPs}
We have implemented the approach to solve MDPs with linear program as in \cite{ANY BOOK}. 
This allows for a combination of strategy iteration to fix one players strategy, and linear programming to solve the induced MDP.
Together with the topological option from \cite{GANDALF}, this yielded one of the most performant algorithms we present in this thesis.